{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import farmhash # https://github.com/veelion/python-farmhash\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "def k_folds_partition(data, hash_column = 'text', n_splits = 10, seed = 43):\n",
    "    set_seed(seed)\n",
    "    data = data.copy()\n",
    "    partition_hash = data[hash_column].apply(lambda x: farmhash.hash64withseed(x, seed))\n",
    "    partition = np.abs(partition_hash % n_splits)\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", 999)\n",
    "pd.set_option(\"max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"D2\"\n",
    "fold = 8\n",
    "date_tag = \"2021_04_08\"\n",
    "data_dir = f\"/hub/CA-MTL/data/{task}\"\n",
    "file = f\"/hub/311_text_classifier/data/raw/PW-{task}-{date_tag}-PROD.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f\"{data_dir}/{date_tag}\"\n",
    "train_file_out = f\"{out_dir}/train.tsv\"\n",
    "train_dev_file_out = f\"{out_dir}/train-dev.tsv\"\n",
    "dev_file_out = f\"{out_dir}/dev.tsv\"\n",
    "test_file_out = f\"{out_dir}/test.tsv\"\n",
    "metadata_file_out = f\"{out_dir}/metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = dict(\n",
    "    raw_data_file = file, \n",
    "    data_version = date_tag, \n",
    "    task_name = task, \n",
    "    file_paths = {\n",
    "        'train':train_file_out, \n",
    "        'train-dev':train_dev_file_out, \n",
    "        'dev':dev_file_out, \n",
    "        'test':test_file_out\n",
    "    },\n",
    "    partition_rules = [\n",
    "        'external/daupler seperate; train/train_dev 0.85/0.15; dev/test 0.5/0.5'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(out_dir)\n",
    "except OSError as error:\n",
    "    print(\"Directory already exists\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and remove all tabs, multi-spaces, and new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tabs_newlines(x):\n",
    "    return re.sub(r\"[\\n\\t\\r]*\", \"\", x)\n",
    "def remove_multi_spaces(x):\n",
    "    return re.sub(r\"\\s\\s+\", \" \", x)\n",
    "data['text'] = data['text'].apply(remove_tabs_newlines)\n",
    "data['text'] = data['text'].apply(remove_multi_spaces)\n",
    "data = data.drop_duplicates('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition External Data in Train and Train-Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['partition'] = k_folds_partition(\n",
    "    data, hash_column = 'text', n_splits = 10, seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_condition = data['partition']!=fold\n",
    "train = data[train_condition].reset_index(drop=True)\n",
    "train_dev = data[~train_condition].reset_index(drop=True)\n",
    "dev = data[~train_condition].reset_index(drop=True)\n",
    "test = data[~train_condition].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['labels'] = data['category'].sort_values().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = {\n",
    "    'D0':[\n",
    "        'text',\n",
    "        'category',\n",
    "        'internal_id',\n",
    "        'external_id'\n",
    "    ],\n",
    "    'D1':[\n",
    "        'text',\n",
    "        'category',\n",
    "        'internal_id',\n",
    "        'external_id'\n",
    "    ],\n",
    "    'D2':[\n",
    "        'text',\n",
    "        'category',\n",
    "        'qualifier'\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[out_cols[task]].to_csv(train_file_out,sep='\\t',index=False)\n",
    "train_dev[out_cols[task]].to_csv(train_dev_file_out,sep='\\t',index=False)\n",
    "dev[out_cols[task]].to_csv(dev_file_out,sep='\\t',index=False)\n",
    "test[out_cols[task]].to_csv(test_file_out,sep='\\t',index=False)\n",
    "json.dump(metadata, open(metadata_file_out, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python run.py \\\n",
    "--model_name_or_path CA-MTL-tiny \\\n",
    "--data_dir /hub/CA-MTL/data \\\n",
    "--output_dir /hub/CA-MTL/mock_models \\\n",
    "--tasks D0 D1 \\\n",
    "--overwrite_cache \\\n",
    "--task_data_folders D0/2021_04_08 D1/2021_04_08 \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--do_predict \\\n",
    "--evaluate_during_training \\\n",
    "--per_device_train_batch_size 32 \\\n",
    "--per_device_eval_batch_size 32 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--adam_epsilon 1e-8 \\\n",
    "--num_train_epochs 7 \\\n",
    "--warmup_steps 0 \\\n",
    "--save_steps 10000 \\\n",
    "--seed 43\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move dev set to output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate 10-Fold Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dictionary of files for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/hub/CA-MTL/mock_models/\"\n",
    "runs = [\n",
    "    'vibrant-river-1',\n",
    "    'colorful-elevator-2',\n",
    "    'super-deluge-3',\n",
    "    'elated-wave-5',\n",
    "    'magic-lake-6',\n",
    "    'neat-wind-7',\n",
    "    'faithful-music-8',\n",
    "    'winter-bush-9',\n",
    "    'stellar-paper-10',\n",
    "    'still-glade-11'\n",
    "]\n",
    "files = os.listdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_files = defaultdict(defaultdict)\n",
    "for run in runs:\n",
    "    for d in ['D0', 'D1']:\n",
    "        run_files[run][d] = {}\n",
    "        for partition in ['test', 'dev']:\n",
    "            run_files[run][d][partition] = [\n",
    "                file for file in files if (run in file) & file.startswith(f\"{d}_{partition}\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for each partition run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = defaultdict(defaultdict)\n",
    "for run in runs:\n",
    "    for d in ['D0', 'D1']:\n",
    "        data = pd.read_csv(\n",
    "            f\"{model_dir}/{run_files[run][d]['dev'][0]}\", sep=\"\\t\")\n",
    "        data['prediction'] = pd.read_csv(\n",
    "            f\"{model_dir}/{run_files[run][d]['test'][0]}\", sep=\"\\t\")['prediction']\n",
    "        data['run'] = run\n",
    "        run_data[run][d] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append data into a single frame for metric analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0_data = pd.DataFrame()\n",
    "d1_data = pd.DataFrame()\n",
    "for run in run_data.keys():\n",
    "    d0_data = d0_data.append(run_data[run]['D0'], ignore_index = True)\n",
    "    d1_data = d1_data.append(run_data[run]['D1'], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate metrics across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../311_text_classifier/src\")\n",
    "from models.evaluate import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metrics['D0'] = get_metrics(\n",
    "    data=d0_data, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "            labels=d0_data[\"category\"].unique().tolist())\n",
    "metrics['D1'] = get_metrics(\n",
    "    data=d1_data, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "            labels=d1_data[\"category\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['D0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['D1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate metrics by fold and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics = {}\n",
    "run_metrics['D0'] = {}\n",
    "run_metrics['D1'] = {}\n",
    "for run in runs:\n",
    "    d0_temp = d0_data[d0_data['run']==run].copy()\n",
    "    d1_temp = d1_data[d1_data['run']==run].copy()\n",
    "    \n",
    "    run_metrics['D0'][run] = get_metrics(\n",
    "        data=d0_temp, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "        labels=d0_temp[\"category\"].unique().tolist())\n",
    "    run_metrics['D1'][run] = get_metrics(\n",
    "        data=d1_temp, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "        labels=d1_temp[\"category\"].unique().tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics = pd.DataFrame()\n",
    "d0_f1, d1_f1 = [], []\n",
    "for run in runs:\n",
    "    d0_f1.append(run_metrics['D0'][run].loc[0, 'f1'])\n",
    "    d1_f1.append(run_metrics['D1'][run].loc[0, 'f1'])\n",
    "\n",
    "temp = pd.DataFrame({\n",
    "    \"wghtd_f1\":d0_f1+d1_f1, \n",
    "    \"D\":[f\"D0\"]*len(runs) + [f\"D1\"]*len(runs)})\n",
    "plot_metrics = plot_metrics.append(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15, 8))\n",
    "f.suptitle(f\"Weighted F1 Performance on Daupler vs External Data\\n(CA-MTL: tinyBERT)\", \n",
    "          fontsize=18)\n",
    "gs = f.add_gridspec(1, 1)\n",
    "f.patch.set_facecolor('white')\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = f.add_subplot(gs[0, 0])\n",
    "    sns.violinplot(x=\"D\", y=\"wghtd_f1\", data=plot_metrics)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate metrics by fold and source and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0_data['daupler_generated'] = np.where(\n",
    "    d0_data['external_id'].str.contains('daupler'), 1, 0)\n",
    "d1_data['daupler_generated'] = np.where(\n",
    "    d1_data['external_id'].str.contains('daupler'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_metrics = {}\n",
    "source_metrics['D0'] = defaultdict(defaultdict)\n",
    "source_metrics['D1'] = defaultdict(defaultdict)\n",
    "for run in runs:\n",
    "    d0_dau = d0_data[\n",
    "        (d0_data['run']==run) & (d0_data['daupler_generated']==1)].copy()\n",
    "    d0_ext = d0_data[\n",
    "        (d0_data['run']==run) & (d0_data['daupler_generated']!=1)].copy()\n",
    "    d1_dau = d1_data[\n",
    "        (d1_data['run']==run) & (d1_data['daupler_generated']==1)].copy()\n",
    "    d1_ext = d0_data[\n",
    "        (d1_data['run']==run) & (d1_data['daupler_generated']!=1)].copy()\n",
    "    \n",
    "    source_metrics['D0'][run]['dau'] = get_metrics(\n",
    "        data=d0_dau, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "        labels=d0_dau[\"category\"].unique().tolist())\n",
    "    source_metrics['D0'][run]['ext'] = get_metrics(\n",
    "        data=d0_ext, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "        labels=d0_ext[\"category\"].unique().tolist())\n",
    "        \n",
    "    source_metrics['D1'][run]['dau'] = get_metrics(\n",
    "        data=d1_dau, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "        labels=d1_dau[\"category\"].unique().tolist()) \n",
    "    source_metrics['D1'][run]['ext'] = get_metrics(\n",
    "        data=d1_ext, true_y=\"category\", predicted_y=f\"prediction\", \n",
    "        labels=d1_ext[\"category\"].unique().tolist())     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics = pd.DataFrame()\n",
    "for source in ['ext', 'dau']:\n",
    "    d0_f1, d1_f1 = [], []\n",
    "    for run in runs:\n",
    "        d0_f1.append(source_metrics['D0'][run][source].loc[0, 'f1'])\n",
    "        d1_f1.append(source_metrics['D1'][run][source].loc[0, 'f1'])\n",
    "\n",
    "    temp = pd.DataFrame({\n",
    "        \"wghtd_f1\":d0_f1+d1_f1, \n",
    "        \"D\":[f\"D0_{source}\"]*len(runs) + [f\"D1_{source}\"]*len(runs)})\n",
    "    plot_metrics = plot_metrics.append(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15, 8))\n",
    "f.suptitle(f\"Weighted F1 Performance on Daupler vs External Data\\n(CA-MTL: tinyBERT)\", \n",
    "           fontsize=18)\n",
    "gs = f.add_gridspec(1, 1)\n",
    "f.patch.set_facecolor('white')\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = f.add_subplot(gs[0, 0])\n",
    "    sns.violinplot(x=\"D\", y=\"wghtd_f1\", data=plot_metrics)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca-mtl-env",
   "language": "python",
   "name": "ca-mtl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
