{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import farmhash # https://github.com/veelion/python-farmhash\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "def train_test_partition(data, hash_column = 'text', train_pct = 0.8, \n",
    "                         partition_names = ['Train', 'Test'], seed = 43):\n",
    "    set_seed(seed)\n",
    "    threshold = int(train_pct*100)\n",
    "    data = data.copy()\n",
    "    partition_hash = data[hash_column].apply(lambda x: farmhash.hash64withseed(x, seed))\n",
    "    partition = np.abs(partition_hash % 100)\n",
    "    partition = np.where(partition>=threshold, partition_names[1], partition_names[0])\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", 999)\n",
    "pd.set_option(\"max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"D0\"\n",
    "date_tag = \"2021_05_17\"\n",
    "data_dir = f\"/hub/CA-MTL/data/{task}\"\n",
    "file = f\"/hub/311_text_classifier/data/raw/PW-{task}-{date_tag}-PROD.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f\"{data_dir}/{date_tag}\"\n",
    "train_file_out = f\"{out_dir}/train.tsv\"\n",
    "train_dev_file_out = f\"{out_dir}/train-dev.tsv\"\n",
    "dev_file_out = f\"{out_dir}/dev.tsv\"\n",
    "test_file_out = f\"{out_dir}/test.tsv\"\n",
    "metadata_file_out = f\"{out_dir}/metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = dict(\n",
    "    raw_data_file = file, \n",
    "    data_version = date_tag, \n",
    "    task_name = task, \n",
    "    file_paths = {\n",
    "        'train':train_file_out, \n",
    "        'train-dev':train_dev_file_out, \n",
    "        'dev':dev_file_out, \n",
    "        'test':test_file_out\n",
    "    },\n",
    "    partition_rules = [\n",
    "        'external/daupler seperate; train/train_dev 0.85/0.15; dev/test 0.5/0.5'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(out_dir)\n",
    "except OSError as error:\n",
    "    print(\"Directory already exists\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and remove all tabs, multi-spaces, and new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tabs_newlines(x):\n",
    "    return re.sub(r\"[\\n\\t\\r]*\", \"\", x)\n",
    "def remove_multi_spaces(x):\n",
    "    return re.sub(r\"\\s\\s+\", \" \", x)\n",
    "data['text'] = data['text'].apply(remove_tabs_newlines)\n",
    "data['text'] = data['text'].apply(remove_multi_spaces)\n",
    "data = data.drop_duplicates('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remap categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'D1':\n",
    "    remap_condition = (data['D1_category'] == 'Water Meter Issue')\n",
    "    data['D1_category'] = np.where(remap_condition, 'Meter Issue', data['D1_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = data['daupler_generated']==1\n",
    "dau = data[condition].reset_index(drop=True)\n",
    "ext = data[~condition].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(dau.shape)\n",
    "print(ext.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition External Data in Train and Train-Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext['partition'] = train_test_partition(\n",
    "    ext, hash_column = 'text', train_pct = 0.85, \n",
    "    partition_names = ['Train', 'Train-Dev'], seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_condition = ext['partition']=='Train'\n",
    "train = ext[train_condition].reset_index(drop=True)\n",
    "train_dev = ext[~train_condition].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext.groupby(['category', 'partition']).size().unstack().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition Daupler Data in Dev and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dau['partition'] = train_test_partition(\n",
    "    dau, hash_column = 'text', train_pct = 0.50, \n",
    "    partition_names = ['Dev', 'Test'], seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_condition = dau['partition']=='Dev'\n",
    "dev = dau[dev_condition].reset_index(drop=True)\n",
    "test = dau[~dev_condition].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dau.groupby(['category', 'partition']).size().unstack().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in dev[dev['text'].str.contains('The caller hit a couple pot holes on 3205 Martin Way E, Olympia, WA 98506')].text:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['labels'] = data['category'].sort_values().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = {\n",
    "    'D0':[\n",
    "        'text',\n",
    "        'category',\n",
    "        'internal_id',\n",
    "        'external_id'\n",
    "    ],\n",
    "    'D1':[\n",
    "        'text',\n",
    "        'category',\n",
    "        'internal_id',\n",
    "        'external_id'\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[out_cols[task]].to_csv(train_file_out,sep='\\t',index=False)\n",
    "train_dev[out_cols[task]].to_csv(train_dev_file_out,sep='\\t',index=False)\n",
    "dev[out_cols[task]].to_csv(dev_file_out,sep='\\t',index=False)\n",
    "test[out_cols[task]].to_csv(test_file_out,sep='\\t',index=False)\n",
    "json.dump(metadata, open(metadata_file_out, 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca-mtl-env",
   "language": "python",
   "name": "ca-mtl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
