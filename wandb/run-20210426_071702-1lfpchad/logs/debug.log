2021-04-26 07:17:02,263 INFO    MainThread:2058 [wandb_setup.py:_flush():69] setting env: {}
2021-04-26 07:17:02,263 INFO    MainThread:2058 [wandb_setup.py:_flush():69] setting login settings: {}
2021-04-26 07:17:02,263 INFO    MainThread:2058 [wandb_init.py:_log_setup():336] Logging user logs to /home/datasci/CA-MTL/wandb/run-20210426_071702-1lfpchad/logs/debug.log
2021-04-26 07:17:02,263 INFO    MainThread:2058 [wandb_init.py:_log_setup():337] Logging internal logs to /home/datasci/CA-MTL/wandb/run-20210426_071702-1lfpchad/logs/debug-internal.log
2021-04-26 07:17:02,264 INFO    MainThread:2058 [wandb_init.py:_jupyter_setup():287] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f933aaebc50>
2021-04-26 07:17:02,264 INFO    MainThread:2058 [wandb_init.py:init():369] calling init triggers
2021-04-26 07:17:02,264 INFO    MainThread:2058 [wandb_init.py:init():376] wandb.init called with sweep_config: {}
config: {'output_dir': '/hub/CA-MTL/data/SCORED', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': True, 'evaluate_during_training': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'warmup_steps': 0, 'logging_dir': None, 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'use_mt_uncertainty': False, 'uniform_mt_sampling': False, 'percent_of_max_data_size': 1.0, '__cached__setup_devices': (device(type='cuda'), 1)}
2021-04-26 07:17:02,264 INFO    MainThread:2058 [wandb_init.py:init():391] re-initializing run, found existing run on stack: 2td62e56
2021-04-26 07:17:02,265 INFO    MainThread:2058 [wandb_run.py:finish():1167] finishing run heatxg/huggingface/2td62e56
2021-04-26 07:17:02,265 INFO    MainThread:2058 [wandb_run.py:_atexit_cleanup():1494] got exitcode: 0
2021-04-26 07:17:02,265 INFO    MainThread:2058 [wandb_run.py:_restore():1466] restore
2021-04-26 07:17:02,514 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 831
  total_bytes: 831
}

2021-04-26 07:17:03,002 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 831
  total_bytes: 831
}

2021-04-26 07:17:03,327 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 2908
  total_bytes: 5046
}

2021-04-26 07:17:03,431 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 2908
  total_bytes: 5046
}

2021-04-26 07:17:03,534 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 2908
  total_bytes: 5046
}

2021-04-26 07:17:03,636 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 2908
  total_bytes: 5046
}

2021-04-26 07:17:03,739 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 2908
  total_bytes: 5046
}

2021-04-26 07:17:03,841 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 2908
  total_bytes: 5046
}

2021-04-26 07:17:03,943 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 5046
  total_bytes: 5046
}

2021-04-26 07:17:04,046 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 5046
  total_bytes: 5046
}

2021-04-26 07:17:04,148 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 5046
  total_bytes: 5046
}

2021-04-26 07:17:04,251 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 5046
  total_bytes: 5046
}

2021-04-26 07:17:04,353 INFO    MainThread:2058 [wandb_run.py:_wait_for_finish():1616] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 5046
  total_bytes: 5046
}

2021-04-26 07:17:05,432 INFO    MainThread:2058 [wandb_run.py:_show_files():1838] logging synced files
2021-04-26 07:17:05,435 INFO    MainThread:2058 [wandb_init.py:init():418] starting backend
2021-04-26 07:17:05,435 INFO    MainThread:2058 [backend.py:_multiprocessing_setup():71] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2021-04-26 07:17:05,437 INFO    MainThread:2058 [backend.py:ensure_launched():123] starting backend process...
2021-04-26 07:17:05,461 INFO    MainThread:2058 [backend.py:ensure_launched():128] started backend process with pid: 4971
2021-04-26 07:17:05,462 INFO    MainThread:2058 [wandb_init.py:init():423] backend started and connected
2021-04-26 07:17:05,474 INFO    MainThread:2058 [wandb_init.py:init():463] updated telemetry
2021-04-26 07:17:05,475 INFO    MainThread:2058 [wandb_init.py:init():482] communicating current version
2021-04-26 07:17:05,929 INFO    MainThread:2058 [wandb_init.py:init():487] got version response upgrade_message: "wandb version 0.10.27 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2021-04-26 07:17:05,930 INFO    MainThread:2058 [wandb_init.py:init():495] communicating run to backend with 30 second timeout
2021-04-26 07:17:06,128 INFO    MainThread:2058 [wandb_init.py:init():520] starting run threads in backend
2021-04-26 07:17:06,157 INFO    MainThread:2058 [wandb_run.py:_console_start():1524] atexit reg
2021-04-26 07:17:06,158 INFO    MainThread:2058 [wandb_run.py:_redirect():1371] redirect: SettingsConsole.WRAP
2021-04-26 07:17:06,158 INFO    MainThread:2058 [wandb_run.py:_redirect():1414] Wrapping output streams.
2021-04-26 07:17:06,158 INFO    MainThread:2058 [wandb_run.py:_redirect():1438] Redirects installed.
2021-04-26 07:17:06,158 INFO    MainThread:2058 [wandb_init.py:init():544] run started, returning control to user process
2021-04-26 07:17:06,158 INFO    MainThread:2058 [wandb_watch.py:watch():39] Watching
2021-04-26 07:18:05,259 INFO    MainThread:2058 [wandb_setup.py:_flush():69] setting env: {}
2021-04-26 07:18:05,259 INFO    MainThread:2058 [wandb_setup.py:_flush():69] setting login settings: {}
2021-04-26 07:18:05,259 INFO    MainThread:2058 [wandb_init.py:_log_setup():336] Logging user logs to /home/datasci/CA-MTL/wandb/run-20210426_071805-2dlavqow/logs/debug.log
2021-04-26 07:18:05,260 INFO    MainThread:2058 [wandb_init.py:_log_setup():337] Logging internal logs to /home/datasci/CA-MTL/wandb/run-20210426_071805-2dlavqow/logs/debug-internal.log
2021-04-26 07:18:05,260 INFO    MainThread:2058 [wandb_init.py:init():369] calling init triggers
2021-04-26 07:18:05,260 INFO    MainThread:2058 [wandb_init.py:init():376] wandb.init called with sweep_config: {}
config: {'output_dir': '/hub/CA-MTL/data/SCORED', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': False, 'do_predict': True, 'evaluate_during_training': False, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': -1, 'warmup_steps': 0, 'logging_dir': None, 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 42, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'use_mt_uncertainty': False, 'uniform_mt_sampling': False, 'percent_of_max_data_size': 1.0, '__cached__setup_devices': (device(type='cuda'), 1)}
2021-04-26 07:18:05,260 INFO    MainThread:2058 [wandb_init.py:init():391] re-initializing run, found existing run on stack: 1lfpchad
2021-04-26 07:18:05,262 INFO    MainThread:2058 [wandb_run.py:finish():1167] finishing run heatxg/huggingface/1lfpchad
