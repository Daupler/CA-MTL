{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    EvalPrediction,\n",
    "    BertConfig, \n",
    "    BertTokenizer\n",
    ")\n",
    "\n",
    "from src.model.ca_mtl import CaMtl, CaMtlArguments\n",
    "from src.utils.misc import MultiTaskDataArguments, Split\n",
    "from src.mtl_trainer import MultiTaskTrainer, MultiTaskTrainingArguments\n",
    "from src.data.mtl_dataset import MultiTaskDataset\n",
    "from src.data.task_dataset import TaskDataset\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    EvalPrediction,\n",
    "    BertConfig, \n",
    "    BertTokenizer\n",
    ")\n",
    "\n",
    "from src.model.ca_mtl import CaMtl, CaMtlArguments\n",
    "from src.utils.misc import MultiTaskDataArguments, Split\n",
    "from src.mtl_trainer import MultiTaskTrainer, MultiTaskTrainingArguments\n",
    "from src.data.mtl_dataset import MultiTaskDataset\n",
    "from src.data.task_dataset import TaskDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python run.py \\\n",
    "--model_name_or_path CA-MTL-tiny \\\n",
    "--data_dir /hub/CA-MTL/data \\\n",
    "--output_dir /hub/CA-MTL/mock_models \\\n",
    "--tasks D0 D1 MANC LOC SIGNT \\\n",
    "--overwrite_cache \\\n",
    "--task_data_folders D0/2021_04_08 D1/2021_04_08 MANC/2021_04_08 LOC/2021_04_08 SIGNT/2021_04_08 \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--do_predict \\\n",
    "--evaluate_during_training \\\n",
    "--per_device_train_batch_size 32 \\\n",
    "--per_device_eval_batch_size 32 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--adam_epsilon 1e-8 \\\n",
    "--num_train_epochs 7 \\\n",
    "--warmup_steps 0 \\\n",
    "--save_steps 1500 \\\n",
    "--save_total_limit 1 \\\n",
    "--seed 43\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python run.py \\\n",
    "--model_name_or_path CA-MTL-base \\\n",
    "--data_dir /hub/CA-MTL/data \\\n",
    "--output_dir /hub/CA-MTL/mock_models \\\n",
    "--tasks D0 D1 MANC LOC SIGNT \\\n",
    "--overwrite_cache \\\n",
    "--task_data_folders D0/2021_04_08 D1/2021_04_08 MANC/2021_04_08 LOC/2021_04_08 SIGNT/2021_04_08 \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--do_predict \\\n",
    "--evaluate_during_training \\\n",
    "--per_device_train_batch_size 16 \\\n",
    "--per_device_eval_batch_size 16 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--adam_epsilon 1e-8 \\\n",
    "--num_train_epochs 7 \\\n",
    "--warmup_steps 0 \\\n",
    "--save_steps 1500 \\\n",
    "--save_total_limit 1 \\\n",
    "--seed 43\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python run_inference.py \\\n",
    "--model_name_or_path /hub/CA-MTL/mock_models/vital-smoke-40-9000 \\\n",
    "--data_dir /hub/CA-MTL/data \\\n",
    "--output_dir /hub/CA-MTL/data/SCORED \\\n",
    "--overwrite_cache \\\n",
    "--task_data_folders TOSCORE \\\n",
    "--do_predict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "run.py --model_name_or_path CA-MTL-tiny --data_dir /hub/CA-MTL/data --output_dir /hub/CA-MTL/mock_models --tasks D0 D1 MANC LOC SIGNT --overwrite_cache --task_data_folders D0/2021_04_08 D1/2021_04_08 MANC/2021_04_08 LOC/2021_04_08 SIGNT/2021_04_08 --do_train --do_eval --do_predict --evaluate_during_training --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --learning_rate 5e-5 --adam_epsilon 1e-8 --num_train_epochs 7 --warmup_steps 0 --save_steps 10 --save_total_limit 1 --seed 43\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that predictions do not change when changing the model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/hub/CA-MTL/mock_models\"\n",
    "tasks = ['D0', 'D1', 'LOC', 'MANC', 'SIGNT']\n",
    "orig_model_run = \"leafy-sky-42\"\n",
    "new_model_run = \"radiant-music-89\"\n",
    "orig = {}\n",
    "new = {}\n",
    "for task in tasks:\n",
    "    orig[task] = pd.read_csv(f\"{model_dir}/{task}_test_iter_{orig_model_run}.tsv\", \n",
    "                             sep=\"\\t\")\n",
    "    new[task] = pd.read_csv(f\"{model_dir}/{task}_test_iter_{new_model_run}.tsv\",\n",
    "                            sep=\"\\t\")                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>leafy-sky-42</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -2.1757247447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>leafy-sky-42</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -2.0285027027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>leafy-sky-42</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -1.9623690843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>leafy-sky-42</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -2.1853635311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>leafy-sky-42</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -1.5310235023...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index scoring_model        prediction  probability  \\\n",
       "0      0  leafy-sky-42  Street Name Sign     0.999564   \n",
       "1      1  leafy-sky-42  Street Name Sign     0.999648   \n",
       "2      2  leafy-sky-42  Street Name Sign     0.999622   \n",
       "3      3  leafy-sky-42  Street Name Sign     0.999646   \n",
       "4      4  leafy-sky-42  Street Name Sign     0.993865   \n",
       "\n",
       "                                              logits  \n",
       "0  {\"Advance Traffic Control Sign\": -2.1757247447...  \n",
       "1  {\"Advance Traffic Control Sign\": -2.0285027027...  \n",
       "2  {\"Advance Traffic Control Sign\": -1.9623690843...  \n",
       "3  {\"Advance Traffic Control Sign\": -2.1853635311...  \n",
       "4  {\"Advance Traffic Control Sign\": -1.5310235023...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>radiant-music-89</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -2.1757247447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>radiant-music-89</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -2.0285027027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>radiant-music-89</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -1.9623690843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>radiant-music-89</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.999646</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -2.1853635311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>radiant-music-89</td>\n",
       "      <td>Street Name Sign</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>{\"Advance Traffic Control Sign\": -1.5310235023...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     scoring_model        prediction  probability  \\\n",
       "0      0  radiant-music-89  Street Name Sign     0.999564   \n",
       "1      1  radiant-music-89  Street Name Sign     0.999648   \n",
       "2      2  radiant-music-89  Street Name Sign     0.999622   \n",
       "3      3  radiant-music-89  Street Name Sign     0.999646   \n",
       "4      4  radiant-music-89  Street Name Sign     0.993865   \n",
       "\n",
       "                                              logits  \n",
       "0  {\"Advance Traffic Control Sign\": -2.1757247447...  \n",
       "1  {\"Advance Traffic Control Sign\": -2.0285027027...  \n",
       "2  {\"Advance Traffic Control Sign\": -1.9623690843...  \n",
       "3  {\"Advance Traffic Control Sign\": -2.1853635311...  \n",
       "4  {\"Advance Traffic Control Sign\": -1.5310235023...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_task = \"SIGNT\"\n",
    "print((orig[check_task]['probability'] == new[check_task]['probability']).mean())\n",
    "display(orig[check_task].head(5))\n",
    "display(new[check_task].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = \"zesty-glitter-82\"\n",
    "model_args = CaMtlArguments(\n",
    "    model_name_or_path=f'/hub/CA-MTL/mock_models/{model_run}-9000', \n",
    "    encoder_type=\"CA-MTL-tiny\")\n",
    "\n",
    "data_args = MultiTaskDataArguments(\n",
    "    data_dir='/hub/CA-MTL/data',\n",
    "    overwrite_cache = True,\n",
    "    task_data_folders=['TOSCORE'])\n",
    "\n",
    "training_args = MultiTaskTrainingArguments(\n",
    "    output_dir='/hub/CA-MTL/data/SCORED', \n",
    "    overwrite_output_dir=False,\n",
    "    do_train=False, do_eval=False,\n",
    "    do_predict=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "def setup_logging(training_args):\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    "    )\n",
    "    logger.warning(\n",
    "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "        training_args.local_rank,\n",
    "        training_args.device,\n",
    "        training_args.n_gpu,\n",
    "        bool(training_args.local_rank != -1),\n",
    "        training_args.fp16,\n",
    "    )\n",
    "def create_eval_datasets(mode, data_args, tokenizer, model_metadata):\n",
    "    eval_datasets = {}\n",
    "    for task_id, task_name in enumerate(model_metadata['tasks']):\n",
    "        eval_datasets[task_name] = TaskDataset(\n",
    "            task_name, task_id, data_args, tokenizer, mode=mode, \n",
    "            label_list=model_metadata['label_set'][task_name]\n",
    "        )\n",
    "    return eval_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/10/2021 06:13:20 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
      "05/10/2021 06:13:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/10/2021 06:13:20 - INFO - __main__ -   MultiTaskTrainingArguments(output_dir='/hub/CA-MTL/data/SCORED', overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=True, evaluate_during_training=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir=None, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, use_mt_uncertainty=False, uniform_mt_sampling=False, percent_of_max_data_size=1.0)\n",
      "05/10/2021 06:13:20 - INFO - transformers.configuration_utils -   loading configuration file /hub/CA-MTL/mock_models/zesty-glitter-82-9000/config.json\n",
      "05/10/2021 06:13:20 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"CaMtl\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"cell\": {},\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_seq_length\": 256,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_tasks\": 5,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pre_trained\": \"\",\n",
      "  \"structure\": [],\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/10/2021 06:13:20 - INFO - transformers.modeling_utils -   loading weights file /hub/CA-MTL/mock_models/zesty-glitter-82-9000/pytorch_model.bin\n",
      "05/10/2021 06:13:29 - INFO - __main__ -   CaMtl(\n",
      "  (bert): CaMtlBaseEncoder(\n",
      "    (task_type_embeddings): Embedding(5, 768)\n",
      "    (conditional_alignment): FiLM(\n",
      "      (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "    )\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): MyBertEncoder9(\n",
      "      (task_transformation): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer9(\n",
      "          (attention): MyBertAttention9(\n",
      "            (self): MyBertSelfAttention9(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (cond_block_diag_attn): CBDA(\n",
      "                (gb_weights): Linear(in_features=768, out_features=172, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (output): MyBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer9(\n",
      "          (attention): MyBertAttention9(\n",
      "            (self): MyBertSelfAttention9(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (cond_block_diag_attn): CBDA(\n",
      "                (gb_weights): Linear(in_features=768, out_features=172, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (output): MyBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer9(\n",
      "          (attention): MyBertAttention9(\n",
      "            (self): MyBertSelfAttention9(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (cond_block_diag_attn): CBDA(\n",
      "                (gb_weights): Linear(in_features=768, out_features=172, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (output): MyBertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): MyBertLayer9(\n",
      "          (attention): MyBertAttention9(\n",
      "            (self): MyBertSelfAttention9(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (cond_block_diag_attn): CBDA(\n",
      "                (gb_weights): Linear(in_features=768, out_features=172, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (output): MyBertSelfOutput9(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): ConditionalLayerNorm(\n",
      "                (768,), 768, eps=1e-12\n",
      "                (ln_weight_modulation): FiLM(\n",
      "                  (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): MyBertOutput9(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): ConditionalLayerNorm(\n",
      "              (768,), 768, eps=1e-12\n",
      "              (ln_weight_modulation): FiLM(\n",
      "                (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): MyBertLayer9(\n",
      "          (attention): MyBertAttention9(\n",
      "            (self): MyBertSelfAttention9(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (cond_block_diag_attn): CBDA(\n",
      "                (gb_weights): Linear(in_features=768, out_features=172, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (output): MyBertSelfOutput9(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): ConditionalLayerNorm(\n",
      "                (768,), 768, eps=1e-12\n",
      "                (ln_weight_modulation): FiLM(\n",
      "                  (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): MyBertOutput9(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): ConditionalLayerNorm(\n",
      "              (768,), 768, eps=1e-12\n",
      "              (ln_weight_modulation): FiLM(\n",
      "                (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): MyBertAdapterLayer9(\n",
      "          (new_attention): MyBertAttention9(\n",
      "            (self): MyBertSelfAttention9(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (cond_block_diag_attn): CBDA(\n",
      "                (gb_weights): Linear(in_features=768, out_features=172, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (output): MyBertSelfOutput9(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): ConditionalLayerNorm(\n",
      "                (768,), 768, eps=1e-12\n",
      "                (ln_weight_modulation): FiLM(\n",
      "                  (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "                )\n",
      "              )\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (new_intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (new_output): MyBertOutput9(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): ConditionalLayerNorm(\n",
      "              (768,), 768, eps=1e-12\n",
      "              (ln_weight_modulation): FiLM(\n",
      "                (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (adapter): BertAdapter9(\n",
      "            (bottleneck): ConditionalBottleNeck(\n",
      "              (emb_transf): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (hidden_modulation): FiLM(\n",
      "                (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "              )\n",
      "              (down_proj_layer): Linear(in_features=768, out_features=256, bias=True)\n",
      "              (up_proj_layer): Linear(in_features=256, out_features=768, bias=True)\n",
      "            )\n",
      "            (condlayernorm): ConditionalLayerNorm(\n",
      "              (768,), 768, eps=1e-12\n",
      "              (ln_weight_modulation): FiLM(\n",
      "                (gb_weights): Linear(in_features=768, out_features=1536, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (model): Linear(in_features=768, out_features=17, bias=True)\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (model): Linear(in_features=768, out_features=114, bias=True)\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (model): Linear(in_features=768, out_features=9, bias=True)\n",
      "    )\n",
      "    (3): Decoder(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (model): Linear(in_features=768, out_features=25, bias=True)\n",
      "    )\n",
      "    (4): Decoder(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (model): Linear(in_features=768, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/10/2021 06:13:29 - INFO - transformers.tokenization_utils -   Model name 'huawei-noah/TinyBERT_General_6L_768D' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'huawei-noah/TinyBERT_General_6L_768D' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/10/2021 06:13:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/huawei-noah/TinyBERT_General_6L_768D/vocab.txt from cache at /home/datasci/.cache/torch/transformers/f3df129df0d2a6b551ca9c604c897a2fffe0138d43f74685fa0fe4837e51f986.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/10/2021 06:13:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/huawei-noah/TinyBERT_General_6L_768D/added_tokens.json from cache at None\n",
      "05/10/2021 06:13:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/huawei-noah/TinyBERT_General_6L_768D/special_tokens_map.json from cache at None\n",
      "05/10/2021 06:13:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/huawei-noah/TinyBERT_General_6L_768D/tokenizer_config.json from cache at None\n"
     ]
    }
   ],
   "source": [
    "setup_logging(training_args)\n",
    "\n",
    "set_seed(training_args.seed)\n",
    "logger.info(training_args)\n",
    "\n",
    "model_metadata = json.load(open(f\"{model_args.model_name_or_path}/metadata.json\", 'r'))\n",
    "\n",
    "# update arguments with condition at model training\n",
    "data_args.max_seq_length = model_metadata['max_seq_length']\n",
    "num_tasks = len(model_metadata['label_set'])\n",
    "data_args.task_data_folders = data_args.task_data_folders*num_tasks\n",
    "data_args.tasks = model_metadata['tasks']\n",
    "model_args.encoder_type = model_metadata['model_name_or_path']\n",
    "\n",
    "config = BertConfig.from_pretrained(model_args.model_name_or_path)\n",
    "config.torchscript=True\n",
    "\n",
    "model = CaMtl.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    model_args,\n",
    "    data_args,\n",
    "    config=config)\n",
    "\n",
    "logger.info(model)\n",
    "\n",
    "# load the tokenizer that was used when the model was trained\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    CaMtl.get_base_model(model_metadata['model_name_or_path']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TSConfig():\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         config_dict\n",
    "#     ):\n",
    "#         self.architectures = config_dict.pop(\"architectures\", None)\n",
    "#         self.attention_probs_dropout_prob = config_dict.pop(\"attention_probs_dropout_prob\", None)\n",
    "#         self.cell = config_dict.pop(\"cell\", None)\n",
    "#         self.hidden_act = config_dict.pop(\"hidden_act\", None)\n",
    "#         self.hidden_dropout_prob = config_dict.pop(\"hidden_dropout_prob\", None)\n",
    "#         self.hidden_size = config_dict.pop(\"hidden_size\", None)\n",
    "#         self.initializer_range = config_dict.pop(\"initializer_range\", None)\n",
    "#         self.intermediate_size = config_dict.pop(\"intermediate_size\", None)\n",
    "#         self.layer_norm_eps = config_dict.pop(\"layer_norm_eps\", None)\n",
    "#         self.max_position_embeddings = config_dict.pop(\"max_position_embeddings\", None)\n",
    "#         self.max_seq_length = config_dict.pop(\"max_seq_length\", None)\n",
    "#         self.model_type = config_dict.pop(\"model_type\", None)\n",
    "#         self.num_attention_heads = config_dict.pop(\"num_attention_heads\", None)\n",
    "#         self.num_hidden_layers = config_dict.pop(\"num_hidden_layers\", None)\n",
    "#         self.num_tasks = config_dict.pop(\"num_tasks\", None)\n",
    "#         self.pad_token_id = config_dict.pop(\"pad_token_id\", None)\n",
    "#         self.pre_trained = config_dict.pop(\"pre_trained\", None)\n",
    "#         self.structure = config_dict.pop(\"structure\", None)\n",
    "#         self.torchscript = config_dict.pop(\"torchscript\", True)\n",
    "#         self.type_vocab_size = config_dict.pop(\"type_vocab_size\", None)\n",
    "#         self.vocab_size = config_dict.pop(\"vocab_size\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_config = TSConfig(config.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaMtlArguments(model_name_or_path='/hub/CA-MTL/mock_models/zesty-glitter-82-9000', encoder_type='CA-MTL-tiny')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskDataArguments(data_dir='/hub/CA-MTL/data', tasks=['D0', 'D1', 'MANC', 'LOC', 'SIGNT'], task_data_folders=['TOSCORE', 'TOSCORE', 'TOSCORE', 'TOSCORE', 'TOSCORE'], overwrite_cache=True, max_seq_length=256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertForSequenceClassification\n",
    "# bert_model = torch.jit.script(BertForSequenceClassification.from_pretrained(\n",
    "#     \"bert-base-uncased\", torchscript=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/10/2021 06:13:31 - INFO - transformers.modeling_utils -   loading weights file /hub/CA-MTL/mock_models/zesty-glitter-82-9000/pytorch_model.bin\n",
      "/home/datasci/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/_recursive.py:165: UserWarning: 'weight' was found in ScriptModule constants,  but it is a non-constant parameter. Consider removing it.\n",
      "  \" but it is a non-constant {}. Consider removing it.\".format(name, hint))\n",
      "/home/datasci/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/_recursive.py:165: UserWarning: 'bias' was found in ScriptModule constants,  but it is a non-constant parameter. Consider removing it.\n",
      "  \" but it is a non-constant {}. Consider removing it.\".format(name, hint))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\nModule 'CaMtlBaseEncoder' has no attribute 'config' (This attribute exists on the Python module, but we failed to convert Python type: 'BertConfig' to a TorchScript type.):\n  File \"/home/datasci/CA-MTL/src/model/encoders/ca_mtl_base.py\", line 676\n                )\n                head_mask = head_mask.expand(\n                    self.config.num_hidden_layers, -1, -1, -1, -1\n                    ~~~~~~~~~~~ <--- HERE\n                )\n            elif head_mask.dim() == 2:\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2494f75758f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     config=config))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_script_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0mqualified_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mconcrete_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcrete_type_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;31m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36m_construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m   1898\u001b[0m             \"\"\"\n\u001b[1;32m   1899\u001b[0m             \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m             \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m             \u001b[0;31m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;31m# use the default recursive rule to compile the module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0mscripted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_concrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0mcpp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mscript_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscripted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mcreate_methods_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_emit_module_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpp_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ca-mtl-env/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_from_stubs\u001b[0;34m(concrete_type, stubs)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mrcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mdefaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_default_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_method\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nModule 'CaMtlBaseEncoder' has no attribute 'config' (This attribute exists on the Python module, but we failed to convert Python type: 'BertConfig' to a TorchScript type.):\n  File \"/home/datasci/CA-MTL/src/model/encoders/ca_mtl_base.py\", line 676\n                )\n                head_mask = head_mask.expand(\n                    self.config.num_hidden_layers, -1, -1, -1, -1\n                    ~~~~~~~~~~~ <--- HERE\n                )\n            elif head_mask.dim() == 2:\n"
     ]
    }
   ],
   "source": [
    "s_model = torch.jit.script(CaMtl.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    model_args=model_args,\n",
    "    data_args=data_args,\n",
    "    config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = torch.Tensor([1, 2, 3, 0, 3, 4, 1, 1, 0, 0, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in this:\n",
    "    print(int(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^ I need to find a way to do this without using .numpy() or the numpy library... maybe I can iterate through the tensor in another way??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = []\n",
    "for i in range(10):\n",
    "    this.append(i)\n",
    "that = []\n",
    "for i in range(10):\n",
    "    that.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this.append(that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(this, that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(this, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original test data\n",
    "# load original test data scores\n",
    "# load deployment test data sample\n",
    "# score test sample with model\n",
    "# score test sample with serialized model\n",
    "# compare all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def predict(\n",
    "#         self,\n",
    "#         eval_dataset: Optional[Dataset] = None,\n",
    "#         prediction_loss_only: Optional[bool] = None,\n",
    "#         scoring_model: Optional[str] = None\n",
    "#     ):\n",
    "#         logging.info(\"*** Test ***\")\n",
    "#         datasets = eval_dataset or self.test_datasets\n",
    "#         for task_name, test_dataset in datasets.items():\n",
    "#             logger.info(task_name)\n",
    "            \n",
    "#             test_dataloader = self.get_test_dataloader(test_dataset)\n",
    "#             test_result = self._prediction_loop(\n",
    "#                 test_dataloader, description=\"Prediction\", task_name=task_name, \n",
    "#                 mode=test_dataset.mode)\n",
    "            \n",
    "#             self._log(test_result.metrics)\n",
    "#             for key, value in test_result.metrics.items():\n",
    "#                 logger.info(\"  %s = %s\", key, value)\n",
    "                \n",
    "#             softmax = torch.nn.Softmax(dim=1)\n",
    "#             probs = softmax(torch.Tensor(test_result.predictions)).numpy().astype('float64')\n",
    "#             logits = test_result.predictions.astype('float64')\n",
    "#             output_mode = task_output_modes[task_name] \n",
    "#             if output_mode == \"classification\":\n",
    "#                 predictions = np.argmax(logits, axis=1)\n",
    "            \n",
    "#             self.run_name = wandb.run.name\n",
    "#             output_test_file = os.path.join(\n",
    "#                 self.args.output_dir,\n",
    "#                 f\"{task_name}_test_iter_{self.run_name}.tsv\",\n",
    "#             )\n",
    "#             if scoring_model is None:\n",
    "#                 scoring_model = self.run_name\n",
    "#             if self.is_world_master():\n",
    "#                 with open(output_test_file, \"w\") as writer:\n",
    "#                     logger.info(\"***** Test results {} *****\".format(task_name))\n",
    "#                     logger.info(\"***** Writing as {} *****\".format(self.run_name))\n",
    "#                     if output_mode == \"regression\":\n",
    "#                         writer.write(\"index\\tprediction\\n\")\n",
    "#                     else:\n",
    "#                         writer.write(\"index\\tscoring_model\\tprediction\\tprobability\\tlogits\\n\")\n",
    "#                     for index, item in enumerate(predictions):\n",
    "#                         if output_mode == \"regression\":\n",
    "#                             writer.write(\"%d\\t%3.3f\\n\" % (index, item))\n",
    "#                         else:\n",
    "#                             i_probs = probs[index,:]\n",
    "#                             i_logits = logits[index,:]\n",
    "#                             i_logits = json.dumps(dict(zip(test_dataset.get_labels(), i_logits)))\n",
    "#                             writer.write(\n",
    "#                                 \"%d\\t%s\\t%s\\t%3.6f\\t%s\\n\" % (\n",
    "#                                     index, scoring_model, test_dataset.get_labels()[item], \n",
    "#                                     i_probs[item], i_logits)\n",
    "#                             )\n",
    "                            \n",
    "#     def _prediction_loop(\n",
    "#         self, dataloader: DataLoader, description: str, task_name: str, mode: str,\n",
    "#         prediction_loss_only: Optional[bool] = None, \n",
    "#     ) -> PredictionOutput:\n",
    "#         \"\"\"\n",
    "#         Prediction/evaluation loop, shared by `evaluate()` and `predict()`.\n",
    "#         Works both with or without labels.\n",
    "#         \"\"\"\n",
    "\n",
    "#         prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else self.prediction_loss_only\n",
    "\n",
    "#         model = self.model\n",
    "#         # multi-gpu eval\n",
    "#         if self.args.n_gpu > 1:\n",
    "#             model = torch.nn.DataParallel(model)\n",
    "#         else:\n",
    "#             model = self.model\n",
    "#         # Note: in torch.distributed mode, there's no point in wrapping the model\n",
    "#         # inside a DistributedDataParallel as we'll be under `no_grad` anyways.\n",
    "\n",
    "#         batch_size = dataloader.batch_size\n",
    "#         logger.info(\"***** Running %s *****\", description)\n",
    "#         logger.info(\"  Num examples = %d\", self.num_examples(dataloader))\n",
    "#         logger.info(\"  Batch size = %d\", batch_size)\n",
    "#         eval_losses: List[float] = []\n",
    "#         preds: torch.Tensor = None\n",
    "#         label_ids: torch.Tensor = None\n",
    "#         model.eval()\n",
    "\n",
    "#         if is_tpu_available():\n",
    "#             dataloader = pl.ParallelLoader(dataloader,\n",
    "#                                            [self.args.device]).per_device_loader(self.args.device)\n",
    "\n",
    "#         for inputs in tqdm(dataloader, desc=description):\n",
    "#             has_labels = any(\n",
    "#                 inputs.get(k) is not None for k in [\"labels\", \"lm_labels\", \"masked_lm_labels\"])\n",
    "\n",
    "#             for k, v in inputs.items():\n",
    "#                 inputs[k] = v.to(self.args.device)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = model(**inputs)\n",
    "#                 if has_labels:\n",
    "#                     step_eval_loss, logits = outputs[:2]\n",
    "#                     eval_losses += [step_eval_loss.mean().item()]\n",
    "#                 else:\n",
    "#                     logits = outputs[0]\n",
    "\n",
    "#             if not prediction_loss_only:\n",
    "#                 if preds is None:\n",
    "#                     preds = logits.detach()\n",
    "#                 else:\n",
    "#                     preds = torch.cat((preds, logits.detach()), dim=0)\n",
    "#                 if inputs.get(\"labels\") is not None:\n",
    "#                     if label_ids is None:\n",
    "#                         label_ids = inputs[\"labels\"].detach()\n",
    "#                     else:\n",
    "#                         label_ids = torch.cat((label_ids, inputs[\"labels\"].detach()), dim=0)\n",
    "\n",
    "#         if self.args.local_rank != -1:\n",
    "#             # In distributed mode, concatenate all results from all nodes:\n",
    "#             if preds is not None:\n",
    "#                 preds = self.distributed_concat(preds,\n",
    "#                                                 num_total_examples=self.num_examples(dataloader))\n",
    "#             if label_ids is not None:\n",
    "#                 label_ids = self.distributed_concat(label_ids,\n",
    "#                                                     num_total_examples=self.num_examples(dataloader))\n",
    "#         elif is_tpu_available():\n",
    "#             # tpu-comment: Get all predictions and labels from all worker shards of eval dataset\n",
    "#             if preds is not None:\n",
    "#                 preds = xm.mesh_reduce(\"eval_preds\", preds, torch.cat)\n",
    "#             if label_ids is not None:\n",
    "#                 label_ids = xm.mesh_reduce(\"eval_label_ids\", label_ids, torch.cat)\n",
    "\n",
    "#         # Finally, turn the aggregated tensors into numpy arrays.\n",
    "#         if preds is not None:\n",
    "#             preds = preds.cpu().numpy()\n",
    "#         if label_ids is not None:\n",
    "#             label_ids = label_ids.cpu().numpy()\n",
    "\n",
    "#         if self.compute_metrics is not None and preds is not None and label_ids is not None:\n",
    "#             metrics = self.compute_metrics(EvalPrediction(predictions=preds, label_ids=label_ids))\n",
    "#         else:\n",
    "#             metrics = {}\n",
    "#         if len(eval_losses) > 0:\n",
    "#             metrics[f\"{task_name}_{mode}_loss\"] = np.mean(eval_losses)\n",
    "\n",
    "#         # Prefix all keys with {task_name}_{model}_\n",
    "#         for key in list(metrics.keys()):\n",
    "#             if not key.startswith(f\"{task_name}_{mode}_\"):\n",
    "#                 metrics[f\"{task_name}_{mode}_{key}\"] = metrics.pop(key)\n",
    "\n",
    "#         return PredictionOutput(predictions=preds, label_ids=label_ids, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.encoders.conditional_modules import CBDA\n",
    "from src.utils.misc import Split\n",
    "import math\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 768\n",
    "max_seq_length = 256\n",
    "num_blocks = hidden_size//max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = CaMtlArguments(\n",
    "    model_name_or_path=\"CA-MTL-tiny\", \n",
    "    encoder_type=\"CA-MTL-tiny\")\n",
    "\n",
    "data_args = MultiTaskDataArguments(\n",
    "    data_dir='/hub/CA-MTL/data',\n",
    "    tasks=['D0', 'D1', 'LOC', 'MANC', 'SIGNT'],\n",
    "    overwrite_cache = True,\n",
    "    task_data_folders=[\n",
    "        'D0/2021_04_08', 'D1/2021_04_08', 'MANC/2021_04_08', \n",
    "        'LOC/2021_04_08', 'SIGNT/2021_04_08'])\n",
    "\n",
    "training_args = MultiTaskTrainingArguments(\n",
    "    output_dir='/hub/CA-MTL/mock_models', \n",
    "    overwrite_output_dir=False, \n",
    "    do_train=True, \n",
    "    do_eval=True, \n",
    "    do_predict=True,\n",
    "    evaluate_during_training=True,\n",
    "    per_device_train_batch_size=32, \n",
    "    per_device_eval_batch_size=32, \n",
    "    per_gpu_train_batch_size=None, \n",
    "    per_gpu_eval_batch_size=None, \n",
    "    gradient_accumulation_steps=1, \n",
    "    learning_rate=5e-05, \n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-08,\n",
    "    max_grad_norm=1.0,\n",
    "    num_train_epochs=7.0, \n",
    "    max_steps=-1, \n",
    "    warmup_steps=0, \n",
    "    logging_dir=None, \n",
    "    logging_first_step=False,\n",
    "    logging_steps=500,\n",
    "    save_steps=1500,\n",
    "    save_total_limit=1, \n",
    "    no_cuda=False, \n",
    "    seed=43, \n",
    "    fp16=False,\n",
    "    fp16_opt_level='O1',\n",
    "    local_rank=-1, \n",
    "    tpu_num_cores=None, \n",
    "    tpu_metrics_debug=False, \n",
    "    use_mt_uncertainty=False, \n",
    "    uniform_mt_sampling=False, \n",
    "    percent_of_max_data_size=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(CaMtl.get_base_model(model_args.model_name_or_path))\n",
    "\n",
    "model = CaMtl.from_pretrained(\n",
    "    CaMtl.get_base_model(model_args.model_name_or_path),\n",
    "    model_args,\n",
    "    data_args,\n",
    "    config=config)\n",
    "\n",
    "logger.info(model)\n",
    "\n",
    "# load the tokenizer that was used when the model was trained\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    CaMtl.get_base_model(model_args.model_name_or_path),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset=MultiTaskDataset(data_args, tokenizer, limit_length=50)\n",
    "\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    if i == 200:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers import (\n",
    "    DefaultDataCollator,\n",
    ")\n",
    "def get_train_dataloader(train_dataset):\n",
    "    sampler = RandomSampler(train_dataset)\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=sampler,\n",
    "        batch_size=32,\n",
    "        collate_fn=DefaultDataCollator().collate_batch,\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "train_dataloader = get_train_dataloader(train_dataset)\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i == 1:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id_2_task_idx = {i: i for i, t in enumerate(data_args.tasks)}\n",
    "def _create_task_type(task_id):\n",
    "    task_type = task_id.clone()\n",
    "    unique_task_ids = torch.unique(task_type)\n",
    "    unique_task_ids_list = (\n",
    "        unique_task_ids.cpu().numpy()\n",
    "        if unique_task_ids.is_cuda\n",
    "        else unique_task_ids.numpy()\n",
    "    )\n",
    "    for unique_task_id in unique_task_ids_list:\n",
    "        task_type[task_type == unique_task_id] = task_id_2_task_idx[\n",
    "            unique_task_id\n",
    "        ]\n",
    "    return task_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(train_dataloader).next()\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = _create_task_type(batch['task_id'])\n",
    "\n",
    "task_type_embeddings = nn.Embedding(len(data_args.tasks), hidden_size)\n",
    "task_embedding = task_type_embeddings(task_type)\n",
    "\n",
    "task_transformation = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "task_embedding = task_transformation(task_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_weight_matrix = nn.Parameter(\n",
    "    torch.zeros(\n",
    "        [max_seq_length, math.ceil(max_seq_length/num_blocks)]\n",
    "    ),\n",
    "    requires_grad=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_weight_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_block_diag_attn = CBDA(\n",
    "    hidden_size, math.ceil(max_seq_length/num_blocks), num_blocks\n",
    ")  # d x L/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores = cond_block_diag_attn(\n",
    "    x_cond=task_embedding,\n",
    "    x_to_film=random_weight_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END CBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 10\n",
    "# setup_logging(training_args)\n",
    "\n",
    "# set_seed(training_args.seed)\n",
    "# logger.info(training_args)\n",
    "\n",
    "# model_metadata = json.load(open(f\"{model_args.model_name_or_path}/metadata.json\", 'r'))\n",
    "\n",
    "# # update arguments with condition at model training\n",
    "# data_args.max_seq_length = model_metadata['max_seq_length']\n",
    "# num_tasks = len(model_metadata['label_set'])\n",
    "# data_args.task_data_folders = data_args.task_data_folders*num_tasks\n",
    "# data_args.tasks = model_metadata['tasks']\n",
    "# model_args.encoder_type = model_metadata['model_name_or_path']\n",
    "\n",
    "# config = BertConfig.from_pretrained(model_args.model_name_or_path)\n",
    "\n",
    "# model = CaMtl.from_pretrained(\n",
    "#     model_args.model_name_or_path,\n",
    "#     model_args,\n",
    "#     data_args,\n",
    "#     config=config)\n",
    "\n",
    "# logger.info(model)\n",
    "\n",
    "# # load the tokenizer that was used when the model was trained\n",
    "# tokenizer = BertTokenizer.from_pretrained(\n",
    "#     CaMtl.get_base_model(model_metadata['model_name_or_path']),\n",
    "# )\n",
    "\n",
    "# logger.info(\"Training tasks: %s\", \", \".join([t for t in data_args.tasks]))\n",
    "\n",
    "# trainer = MultiTaskTrainer(\n",
    "#     tokenizer,\n",
    "#     data_args,\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=None,\n",
    "#     eval_datasets=None,\n",
    "#     test_datasets=create_eval_datasets(Split.test, data_args, tokenizer, model_metadata)\n",
    "#     if training_args.do_predict\n",
    "#     else None,\n",
    "# )\n",
    "\n",
    "# scoring_model = model_args.model_name_or_path.split(\"/\")[-1]\n",
    "# if training_args.do_predict:\n",
    "#     trainer.predict(scoring_model = scoring_model)\n",
    "# 1min 1s ± 256 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca-mtl-env",
   "language": "python",
   "name": "ca-mtl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
